{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 𝐇𝐲𝐩𝐨𝐭𝐡𝐞𝐭𝐢𝐜𝐚𝐥 𝐃𝐨𝐜𝐮𝐦𝐞𝐧𝐭 𝐄𝐦𝐛𝐞𝐝𝐝𝐢𝐧𝐠 (𝐇𝐲𝐃𝐄)\n",
    "\n",
    "In a standard retriever-augmented generation (RAG) workflow, retrieval typically involves comparing the embedding vector of a query with the embedding vectors of document chunks to find the most relevant matches. However, this approach has limitations, especially in zero-shot dense retrieval. The challenge arises because query and document embeddings must exist in the same vector space, even though questions and documents are fundamentally different. Queries are often short, ambiguous, or poorly phrased, while documents contain structured, detailed information.\n",
    "\n",
    "\n",
    "\n",
    "𝐇𝐨𝐰 𝐇𝐲𝐃𝐄 𝐈𝐦𝐩𝐫𝐨𝐯𝐞𝐬 𝐑𝐞𝐭𝐫𝐢𝐞𝐯𝐚𝐥\n",
    "\n",
    "HyDE addresses this by mapping queries into the document space using hypothetical documents. Instead of directly embedding the question, we use a language model (LLM) to generate a synthetic passage based on the query. We then perform vector search using this generated passage rather than the raw question, leading to better alignment with document embeddings.\n",
    "\n",
    "\n",
    "\n",
    "𝐖𝐡𝐞𝐧 𝐭𝐨 𝐔𝐬𝐞 𝐇𝐲𝐃𝐄\n",
    "\n",
    "✅ Boosting retrieval performance when recall is low\n",
    "\n",
    "✅ Handling large document spaces where standard retrieval struggles\n",
    "\n",
    "✅ Cross-domain retrieval, especially when documents come from a different domain than the retriever was trained on\n",
    "\n",
    "\n",
    "\n",
    "If your RAG pipeline has recall issues or operates in a challenging domain, HyDE is definitely worth exploring! 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Arun.Mohan/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai,os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from typing import DefaultDict\n",
    "from azure.identity import ClientSecretCredential\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_access_token():\n",
    "    \"\"\" \n",
    "    gets api key by authenticating with azure ad\n",
    "    \"\"\"\n",
    "    credential = ClientSecretCredential(os.getenv('OPENAI_AD_TENANT_ID'), os.getenv('OPENAI_AD_CLIENT_ID'),\n",
    "                                            os.getenv('OPENAI_AD_CLIENT_SECRET'))\n",
    "    access_token = credential.get_token(os.getenv('OPENAI_AD_TOKEN_BASE'))\n",
    "    return access_token.token "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before getting to hyDe lets embedd some documents in to vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Docs = [\n",
    "\n",
    "\"EV batteries primarily use lithium-ion chemistry, known for high energy density and rechargeability. Other components include cobalt, nickel, manganese, and graphite, each influencing performance, cost, and safety.\",\n",
    "\"Solid-state batteries are emerging as a promising alternative to conventional lithium-ion batteries. They offer increased energy density, faster charging, and improved safety due to the absence of liquid electrolytes.\",\n",
    "\"Legacy automakers like Ford, GM, and Volkswagen have invested billions in EV development, with GM committing to an all-electric future by 2035. These investments cover vehicle platforms, battery plants, and EV-specific R&D.\",\n",
    "\"Tech companies like Apple and Xiaomi are also exploring EVs, either through direct vehicle development or software and autonomous systems. Their entry reflects how EVs are becoming a convergence point for the auto and tech industries.\",\n",
    "\"Public charging infrastructure is critical for EV adoption, with fast chargers (DCFC) reducing charging times to under 30 minutes. Countries like China and the U.S. are rapidly expanding nationwide networks.\",\n",
    "\"Home charging accounts for over 80% of EV charging, making Level 2 residential chargers an essential part of the ecosystem. Incentives often cover installation costs to promote at-home charging convenience.\",\n",
    "\"Many EVs are integrated with advanced driver-assistance systems (ADAS), leveraging sensors, AI, and over-the-air updates. Tesla's Autopilot and Rivian’s Driver+ are examples of smart EV technologies evolving toward autonomy.\",\n",
    "\"Global EV sales surpassed 14 million units in 2023, representing nearly 18% of all new car sales. Asia, especially China, leads the market, but Europe and North America are also seeing rapid growth\",\n",
    "\"EVs produce zero tailpipe emissions, making them a cleaner alternative to internal combustion engine vehicles. However, lifecycle emissions depend on how electricity is generated.\",\n",
    "\"Battery recycling and reuse are becoming crucial to EV sustainability. Companies like Redwood Materials are working on systems to recover lithium, cobalt, and nickel from end-of-life batteries to reduce mining and environmental impact.\"\n",
    "\n",
    "]\n",
    "\n",
    "### initialize a embedding model\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "def get_emebeddding_model():\n",
    "\n",
    "    \n",
    "\n",
    "    embedding_model = AzureOpenAIEmbeddings(\n",
    "                # azure_deployment=os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL_NAME\"),\n",
    "                model=os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL_NAME\"),\n",
    "                azure_endpoint=os.getenv(\"AZURE_OPENAI_EMBEDDING_BASE\"),\n",
    "                openai_api_version=os.getenv('AZURE_OPENAI_API_VERSION'),\n",
    "                openai_api_key=get_access_token()\n",
    "    )\n",
    "    return embedding_model\n",
    "\n",
    "\n",
    "embedding_model = get_emebeddding_model()\n",
    "\n",
    "\n",
    "\n",
    "# Create a vector store with a documents\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vectorstore = InMemoryVectorStore.from_texts(\n",
    "    Docs,\n",
    "    embedding=embedding_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step of HyDE is to ask llm to generate an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import SystemMessagePromptTemplate,HumanMessagePromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "\n",
    "def get_llm_gen_answer_prompt_template():\n",
    "\n",
    "    system_message = \"\"\"\"Given a question, generate a paragraph under 30 words of text that answers the question\"\"\"\n",
    "\n",
    "    user_message = \"\"\"Question: {question}\n",
    "                      Paragraph:\"\"\"\n",
    "\n",
    "    system_prompt = SystemMessagePromptTemplate.from_template(system_message)\n",
    "    user_prompt = HumanMessagePromptTemplate.from_template(user_message)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                system_prompt,\n",
    "                user_prompt\n",
    "            ]\n",
    "        )\n",
    "    return prompt\n",
    "\n",
    "\n",
    "\n",
    "def get_llm():\n",
    "\n",
    "    api_key = get_access_token()\n",
    "\n",
    "    llm = AzureChatOpenAI(\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_API_BASE\"),\n",
    "        model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "        openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "        api_key=api_key\n",
    "    )\n",
    "    return llm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import chain\n",
    "# Define the LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "## initialize llm\n",
    "llm = get_llm()\n",
    "\n",
    "##prompt template\n",
    "prompt_template = get_llm_gen_answer_prompt_template()\n",
    "\n",
    "\n",
    "# Create a chain\n",
    "gen_context_chain = (\n",
    "        prompt_template\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global EV sales are surging, driven by increasing environmental awareness, government incentives, and advancements in battery technology, resulting in record growth and expanding market adoption worldwide.\n"
     ]
    }
   ],
   "source": [
    "query = \"How is EV sale performing globally?\"\n",
    "\n",
    "\n",
    "\n",
    "# Pass the user input\n",
    "suggested_context = gen_context_chain.invoke({\n",
    "        \"question\": query\n",
    "    })\n",
    "print(suggested_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using this response we will search again vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='7fcad0ff-e779-4382-98d4-c3f4c959a2ba', metadata={}, page_content='Global EV sales surpassed 14 million units in 2023, representing nearly 18% of all new car sales. Asia, especially China, leads the market, but Europe and North America are also seeing rapid growth'),\n",
       "  0.7600522387425275),\n",
       " (Document(id='bafe51a9-7be0-4d6d-b0d1-3b4d6b669faa', metadata={}, page_content='Legacy automakers like Ford, GM, and Volkswagen have invested billions in EV development, with GM committing to an all-electric future by 2035. These investments cover vehicle platforms, battery plants, and EV-specific R&D.'),\n",
       "  0.5491659680277841),\n",
       " (Document(id='4e47c171-c5e1-4626-9459-94d095d4a3fa', metadata={}, page_content=\"Many EVs are integrated with advanced driver-assistance systems (ADAS), leveraging sensors, AI, and over-the-air updates. Tesla's Autopilot and Rivian’s Driver+ are examples of smart EV technologies evolving toward autonomy.\"),\n",
       "  0.5123516244543715)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_chunks(query,k):\n",
    "    retrieved_documents = vectorstore.similarity_search_with_score(k=k,query=query,sorted=True)\n",
    "\n",
    "    return retrieved_documents\n",
    "\n",
    "chunks = get_chunks(query=suggested_context,k=3)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_retriever_prompt_template():\n",
    "\n",
    "    system_message = \"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.\"\n",
    "\n",
    "    user_message = \"\"\"Context: {context}\n",
    "                        Question: {question}\n",
    "                        Answer:\"\"\"\n",
    "\n",
    "    system_prompt = SystemMessagePromptTemplate.from_template(system_message)\n",
    "    user_prompt = HumanMessagePromptTemplate.from_template(user_message)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                system_prompt,\n",
    "                user_prompt\n",
    "            ]\n",
    "        )\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## initialize llm\n",
    "llm = get_llm()\n",
    "\n",
    "##prompt template\n",
    "prompt_template = get_retriever_prompt_template()\n",
    "\n",
    "# Create a chain\n",
    "answer_chain = (\n",
    "        prompt_template\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global EV sales are performing strongly, surpassing 14 million units in 2023, which accounts for nearly 18% of all new car sales. The market is particularly led by Asia, especially China, while Europe and North America are also experiencing rapid growth.\n"
     ]
    }
   ],
   "source": [
    "## run the chain\n",
    "\n",
    "context = \"\\n\\n\".join([doc[0].page_content for doc in chunks])\n",
    "\n",
    "\n",
    "# Pass the user input\n",
    "response = answer_chain.invoke({\n",
    "        \"context\": context,\n",
    "        \"question\": query\n",
    "    })\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
